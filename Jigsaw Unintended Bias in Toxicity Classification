2019 Kaggle competition
Jigsaw Unintended Bias in Toxicity Classification

06/08 issue
- 결측치, correlation 높은 것 확인
- keras보다 pytorch로 하면 빠름
- cleansing 정도의 따른 성능(####과 같은 것도 의미가 있을 수 있음 -> spelling error와 축약형만 처리, 
                                                                소문자로 통일하는 것을 뺏더니 성능이 더 좋은 경우가 있음)
- time문제 -> pickle, train data set의 memory줄이기

https://www.kaggle.com/timon88/bert-lstm-simple-blender-0-93844-lb/data
https://www.kaggle.com/bminixhofer/simple-lstm-pytorch-version
https://www.kaggle.com/kunwar31/simple-lstm-with-identity-parameters-fastai/notebook
def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))
    
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype('category')

    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    
    return df
